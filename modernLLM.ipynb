{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24754a4-91c4-4a8e-9425-6e392fbec975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T14:37:58.608144Z",
     "iopub.status.busy": "2025-02-16T14:37:58.607543Z",
     "iopub.status.idle": "2025-02-16T14:38:06.899411Z",
     "shell.execute_reply": "2025-02-16T14:38:06.898325Z",
     "shell.execute_reply.started": "2025-02-16T14:37:58.608100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ashaba1in/small_openwebtext\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "print(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227b84dc-1ee0-4cf7-9a27-ac8b61629be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T14:38:06.901831Z",
     "iopub.status.busy": "2025-02-16T14:38:06.901183Z",
     "iopub.status.idle": "2025-02-16T14:38:06.973550Z",
     "shell.execute_reply": "2025-02-16T14:38:06.972754Z",
     "shell.execute_reply.started": "2025-02-16T14:38:06.901785Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from llama_modeling import Llama\n",
    "from llama_modeling import MultiheadAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f66893b-bf14-48d2-81da-3f023f1aa787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T14:38:06.974601Z",
     "iopub.status.busy": "2025-02-16T14:38:06.974371Z",
     "iopub.status.idle": "2025-02-16T14:38:36.946381Z",
     "shell.execute_reply": "2025-02-16T14:38:36.945268Z",
     "shell.execute_reply.started": "2025-02-16T14:38:06.974579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n",
      "llama3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length):\n",
    "        self.dataset = dataset['train']\n",
    "        #self.dataset = [item for item in dataset['train'] if len(item[\"text\"]) > 2000]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset[idx][\"text\"]\n",
    "        tokens = self.tokenizer(\n",
    "            text, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\"\n",
    "        ) \n",
    "\n",
    "        input_ids = tokens[\"input_ids\"].squeeze(0)\n",
    "        labels = input_ids[1:].clone()\n",
    "        input_ids = input_ids[:-1]\n",
    "        return input_ids, labels\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "max_length = 256\n",
    "vocab_size = tokenizer.vocab_size + 5\n",
    "embed_dim = 800\n",
    "num_heads = 16\n",
    "head_dim = 50\n",
    "num_layers = 16\n",
    "\n",
    "model = Llama(vocab_size, embed_dim, num_heads, head_dim, max_length, num_layers, device).to(device)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(dataset, tokenizer, max_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d428f44-4bfe-4339-b972-115aba0b872b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T14:38:36.948209Z",
     "iopub.status.busy": "2025-02-16T14:38:36.947859Z",
     "iopub.status.idle": "2025-02-16T14:38:36.957935Z",
     "shell.execute_reply": "2025-02-16T14:38:36.955671Z",
     "shell.execute_reply.started": "2025-02-16T14:38:36.948183Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.1)\n",
    "\n",
    "total_steps = 1_000_000\n",
    "warmup_steps = int(0.001 * total_steps)  \n",
    "\n",
    "def lr_lambda(current_step):\n",
    "    if current_step < warmup_steps:\n",
    "        return current_step / warmup_steps \n",
    "    else:\n",
    "        progress = (current_step - warmup_steps) / (total_steps - warmup_steps)\n",
    "        return 0.5 * (1 + math.cos(math.pi * progress)) \n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df0985f-ed9d-4988-9b39-8b505f54cd86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T14:27:45.961147Z",
     "iopub.status.busy": "2025-02-16T14:27:45.960940Z",
     "iopub.status.idle": "2025-02-16T14:27:46.004858Z",
     "shell.execute_reply": "2025-02-16T14:27:46.003785Z",
     "shell.execute_reply.started": "2025-02-16T14:27:45.961126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего параметров: 153,665,605\n",
      "torch.float32\n",
      "Параметры слоя embed.weight: 25,604,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.0.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.0.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.0.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.0.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.0.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.0.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.0.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.0.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.0.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.1.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.1.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.1.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.1.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.1.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.1.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.1.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.1.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.1.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.2.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.2.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.2.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.2.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.2.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.2.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.2.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.2.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.2.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.3.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.3.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.3.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.3.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.3.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.3.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.3.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.3.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.3.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.4.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.4.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.4.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.4.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.4.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.4.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.4.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.4.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.4.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.5.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.5.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.5.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.5.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.5.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.5.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.5.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.5.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.5.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.6.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.6.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.6.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.6.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.6.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.6.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.6.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.6.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.6.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.7.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.7.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.7.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.7.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.7.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.7.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.7.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.7.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.7.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.8.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.8.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.8.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.8.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.8.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.8.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.8.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.8.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.8.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.9.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.9.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.9.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.9.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.9.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.9.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.9.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.9.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.9.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.10.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.10.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.10.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.10.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.10.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.10.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.10.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.10.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.10.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.11.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.11.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.11.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.11.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.11.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.11.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.11.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.11.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.11.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.12.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.12.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.12.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.12.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.12.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.12.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.12.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.12.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.12.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.13.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.13.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.13.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.13.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.13.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.13.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.13.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.13.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.13.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.14.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.14.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.14.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.14.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.14.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.14.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.14.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.14.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.14.out_proj.weight: 640,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.15.norm1.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.15.MLP.gate_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.15.MLP.up_proj.weight: 1,280,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.15.MLP.down_proj.weight: 1,280,000\n",
      "torch.float32\n",
      "Параметры слоя decoder_blocks.15.norm2.weight: 800\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.15.q_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.15.k_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.15.v_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя decoder_blocks.15.out_proj.weight: 640,000\n",
      "torch.bfloat16\n",
      "Параметры слоя fc_out.weight: 25,604,000\n",
      "torch.bfloat16\n",
      "Параметры слоя fc_out.bias: 32,005\n",
      "\n",
      "Всего параметров: 153,665,605\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Всего параметров: {total_params :,}\")\n",
    "def print_param_count(model):\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        param_count = param.numel() \n",
    "        total_params += param_count\n",
    "        print(param.dtype)\n",
    "        print(f\"Параметры слоя {name}: {param_count:,}\")\n",
    "\n",
    "    print(f\"\\nВсего параметров: {total_params:,}\")\n",
    "print_param_count(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a44a59-b476-4c19-9aa6-7e6a00de145f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T14:38:38.134986Z",
     "iopub.status.busy": "2025-02-16T14:38:38.134656Z",
     "iopub.status.idle": "2025-02-16T17:26:08.376047Z",
     "shell.execute_reply": "2025-02-16T17:26:08.374727Z",
     "shell.execute_reply.started": "2025-02-16T14:38:38.134963Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 12022/14229 [2:47:29<30:44,  1.20it/s, Avg Loss=4.678125, LR=6.89e-06, Samples=1000]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 63\u001B[0m\n\u001B[1;32m     60\u001B[0m     end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m end_time \u001B[38;5;241m-\u001B[39m start_time\n\u001B[0;32m---> 63\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mВремя выполнения \u001B[39m\u001B[38;5;132;01m{\u001B[39;00melapsed_time\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m секунд\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[6], line 24\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m logits, loss \u001B[38;5;241m=\u001B[39m model(x, y)\n\u001B[1;32m     23\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 24\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(x)):\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:140\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m opt \u001B[38;5;241m=\u001B[39m opt_ref()\n\u001B[1;32m    139\u001B[0m opt\u001B[38;5;241m.\u001B[39m_opt_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__get__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    488\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    489\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    490\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    491\u001B[0m             )\n\u001B[0;32m--> 493\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    496\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/adamw.py:243\u001B[0m, in \u001B[0;36mAdamW.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    230\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m cast(Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m], group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    232\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    233\u001B[0m         group,\n\u001B[1;32m    234\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    240\u001B[0m         state_steps,\n\u001B[1;32m    241\u001B[0m     )\n\u001B[0;32m--> 243\u001B[0m     \u001B[43madamw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/adamw.py:875\u001B[0m, in \u001B[0;36madamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    872\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    873\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adamw\n\u001B[0;32m--> 875\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/adamw.py:677\u001B[0m, in \u001B[0;36m_multi_tensor_adamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001B[0m\n\u001B[1;32m    675\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001B[1;32m    676\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 677\u001B[0m     bias_correction1 \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    678\u001B[0m         \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m _get_value(step) \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m device_state_steps\n\u001B[1;32m    679\u001B[0m     ]\n\u001B[1;32m    680\u001B[0m     bias_correction2 \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    681\u001B[0m         \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta2 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m _get_value(step) \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m device_state_steps\n\u001B[1;32m    682\u001B[0m     ]\n\u001B[1;32m    684\u001B[0m     step_size \u001B[38;5;241m=\u001B[39m _stack_if_compiling([(lr \u001B[38;5;241m/\u001B[39m bc) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m bc \u001B[38;5;129;01min\u001B[39;00m bias_correction1])\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/adamw.py:678\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    675\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001B[1;32m    676\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    677\u001B[0m     bias_correction1 \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m--> 678\u001B[0m         \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m device_state_steps\n\u001B[1;32m    679\u001B[0m     ]\n\u001B[1;32m    680\u001B[0m     bias_correction2 \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    681\u001B[0m         \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta2 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m _get_value(step) \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m device_state_steps\n\u001B[1;32m    682\u001B[0m     ]\n\u001B[1;32m    684\u001B[0m     step_size \u001B[38;5;241m=\u001B[39m _stack_if_compiling([(lr \u001B[38;5;241m/\u001B[39m bc) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m bc \u001B[38;5;129;01min\u001B[39;00m bias_correction1])\n",
      "File \u001B[0;32m~/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:106\u001B[0m, in \u001B[0;36m_get_value\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;28;01melse\u001B[39;00m x\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train():\n",
    "    start_time = time.time()\n",
    "    num_epochs = 1  \n",
    "    log_interval = 10\n",
    "    savelog_interval = 10000\n",
    "    save_interval = 100000\n",
    "    samples_processed = 0 \n",
    "    samples_log_processed = 0\n",
    "    avg_loss = 100\n",
    "    i = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_accum = 0.0\n",
    "        with tqdm(enumerate(train_loader, start=1), total=len(train_loader)) as pbar:\n",
    "            for batch_idx, (x, y) in pbar:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                logits, loss = model(x, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                for i in range(len(x)):\n",
    "                    scheduler.step()\n",
    "\n",
    "                loss_accum += loss.item()\n",
    "                samples_processed += len(x)  \n",
    "                samples_log_processed += len(x)\n",
    "                \n",
    "                if batch_idx % log_interval == 0:\n",
    "                    avg_loss = loss_accum / log_interval\n",
    "                    pbar.set_postfix({\n",
    "                        \"Avg Loss\": f\"{avg_loss:.6f}\", \n",
    "                        \"LR\": f\"{optimizer.param_groups[0]['lr']:.2e}\", \n",
    "                        \"Samples\": samples_processed\n",
    "                    })\n",
    "                    loss_accum = 0.0  \n",
    "                    \n",
    "                if samples_log_processed >= savelog_interval:\n",
    "                    with open(\"loss_log42.txt\", \"a\") as f:\n",
    "                        f.write(f\"Epoch {epoch}, Batch {batch_idx}, Avg Loss: {avg_loss:.6f}, LR: {optimizer.param_groups[0]['lr']:.2e}\\n\")\n",
    "                    samples_log_processed = 0\n",
    "                    \n",
    "                if samples_processed >= save_interval:\n",
    "                    checkpoint = {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_idx\": batch_idx,\n",
    "                        \"model_state\": model.state_dict(),\n",
    "                        \"optimizer_state\": optimizer.state_dict(),\n",
    "                        \"scheduler_state\": scheduler.state_dict() if scheduler else None,\n",
    "                        \"loss\": avg_loss,\n",
    "                    }\n",
    "                    torch.save(checkpoint, f\"checkpoint_epoch42_{epoch}_batch_{batch_idx}.pth\")\n",
    "                                        \n",
    "                    samples_processed = 0\n",
    "                i += 1\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "elapsed_time = train()\n",
    "print(f\"Время выполнения {elapsed_time:.2f} секунд\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "226cd7b4-992e-41c0-91b4-16dd1ed08e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T17:28:06.452314Z",
     "iopub.status.busy": "2025-02-16T17:28:06.451485Z",
     "iopub.status.idle": "2025-02-16T17:28:11.516195Z",
     "shell.execute_reply": "2025-02-16T17:28:11.515093Z",
     "shell.execute_reply.started": "2025-02-16T17:28:06.452241Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "def generate_text(model, tokenizer, prompt, max_length=100, temperature=0.8, top_k=25, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            logits = model(input_ids)\n",
    "            logits = logits[:, -1, :]\n",
    "            \n",
    "            logits = logits / temperature\n",
    "            if top_k > 0:\n",
    "\n",
    "                top_k_values, top_k_indices = torch.topk(logits, top_k)\n",
    "                if (top_k_indices < 0).any() or (top_k_indices >= vocab_size).any():\n",
    "                    print(\"Invalid indices detected in top_k_indices!\")\n",
    "                    print(\"Min index:\", top_k_indices.min().item())\n",
    "                    print(\"Max index:\", top_k_indices.max().item())\n",
    "\n",
    "                probs = torch.softmax(top_k_values, dim=-1)\n",
    "                sampled_index = torch.multinomial(probs, 1)\n",
    "                next_token = top_k_indices.gather(-1, sampled_index)\n",
    "\n",
    "            else:\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                \n",
    "                sampled_index = torch.multinomial(probs, 1)\n",
    "                next_token = top_k_indices.gather(-1, sampled_index)\n",
    "\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "\n",
    "            if tokenizer.eos_token_id is not None and next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "    return tokenizer.decode(input_ids.squeeze(), skip_special_tokens=True)\n",
    "\n",
    "prompt = \"I think\"\n",
    "generated_text = generate_text(model, tokenizer, prompt, max_length=200, device = device)\n",
    "print(generated_text)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8195c41-6c4f-48d7-8dc9-fe91036d9004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T14:38:36.961039Z",
     "iopub.status.busy": "2025-02-16T14:38:36.960132Z",
     "iopub.status.idle": "2025-02-16T14:38:38.133597Z",
     "shell.execute_reply": "2025-02-16T14:38:38.132116Z",
     "shell.execute_reply.started": "2025-02-16T14:38:36.960970Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "checkpoint_path = \"checkpoint_epoch4_0_batch_14000.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "epoch = checkpoint[\"epoch\"]\n",
    "batch_idx = checkpoint[\"batch_idx\"]\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state\"])"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
